{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88671a38",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "### Rebecca Hawthorne\n",
    "### 8/1/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c38b0",
   "metadata": {},
   "source": [
    "Answer each question by writing the Python code needed to perform the task. Please only use the libraries requested in each problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d3684",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "Load the interest_inflation data from the statsmodels library as a pandas data frame assigned to `df`. Use the function `df.head()` to view the first 5 rows of the data. Notice the first observation is indexed at 0. Unlike R, Python is a 0 based index language which means when you iterate or wish to view the first observation of a data object it will be at the index 0. \n",
    "\n",
    "What do the columns `Dp` and `R` represent? (You can find this using the documentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723f0215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>Dp</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.003133</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.024804</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1973.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  quarter        Dp      R\n",
       "0  1972.0      2.0 -0.003133  0.083\n",
       "1  1972.0      3.0  0.018871  0.083\n",
       "2  1972.0      4.0  0.024804  0.087\n",
       "3  1973.0      1.0  0.016278  0.087\n",
       "4  1973.0      2.0  0.000290  0.102"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.datasets.interest_inflation.data import load_pandas\n",
    "df = load_pandas().data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07cd73e",
   "metadata": {},
   "source": [
    "Dp is the Delta log gdp deflator\n",
    "R is the nominal long term interest rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b3e2c",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "Import scipy as sp and numpy as np. Using the `mean()` and `var()` function from scipy, validate that both functions equate to their numpy counterparts against the column `Dp`.\n",
    "\n",
    "By using the scipy library you should receive a warning message. What does the warning message indicate? Which function should you use going forward? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83dc8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_10632\\558539862.py:4: DeprecationWarning: scipy.mean is deprecated and will be removed in SciPy 2.0.0, use numpy.mean instead\n",
      "  np.mean(df['Dp']) == sp.mean(df['Dp'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "np.mean(df['Dp']) == sp.mean(df['Dp'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9e3b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_10632\\3874408497.py:1: DeprecationWarning: scipy.var is deprecated and will be removed in SciPy 2.0.0, use numpy.var instead\n",
      "  np.var(df['Dp']) == sp.var(df['Dp'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(df['Dp']) == sp.var(df['Dp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4cf24c",
   "metadata": {},
   "source": [
    "The values calculated by both numpy and scipy are equal. \n",
    "\n",
    "The warning is that scipy.var and scipy.mean have been depreciated and, instead, we should use the numpy versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7334bad9",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Fit an OLS regression (linear regression) using the statsmodels api where `y = df['Dp']` and `x = df['R']`. By default OLS estimates the theoretical mean of the dependent variable y. Statsmodels.ols does not fit a constant value by default so be sure to add a constant to `x`. Extract the coefficients into a variable named `res1_coefs`. See the documentation for `params`. Finally print the `summary()` of the model. \n",
    "\n",
    "Documentation: https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e5d02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const   -0.003126\n",
      "R        0.154512\n",
      "dtype: float64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     Dp   R-squared:                       0.018\n",
      "Model:                            OLS   Adj. R-squared:                  0.009\n",
      "Method:                 Least Squares   F-statistic:                     1.954\n",
      "Date:                Wed, 02 Aug 2023   Prob (F-statistic):              0.165\n",
      "Time:                        20:14:33   Log-Likelihood:                 274.44\n",
      "No. Observations:                 107   AIC:                            -544.9\n",
      "Df Residuals:                     105   BIC:                            -539.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0031      0.008     -0.370      0.712      -0.020       0.014\n",
      "R              0.1545      0.111      1.398      0.165      -0.065       0.374\n",
      "==============================================================================\n",
      "Omnibus:                       11.018   Durbin-Watson:                   2.552\n",
      "Prob(Omnibus):                  0.004   Jarque-Bera (JB):                3.844\n",
      "Skew:                          -0.050   Prob(JB):                        0.146\n",
      "Kurtosis:                       2.077   Cond. No.                         61.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    " import statsmodels.api as sm\n",
    "\n",
    "y = df['Dp']\n",
    "x = df['R']\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y,x)\n",
    "\n",
    "results = model.fit()\n",
    "\n",
    "res1_coefs = results.params\n",
    "\n",
    "print(res1_coefs)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630fe6c",
   "metadata": {},
   "source": [
    "### Probelm 4\n",
    "Fit a quantile regression model using the statsmodels api using the formula `Dp ~ R`. By default quantreg creates a constant so there is no need to add one to this model. In your `fit()` method be sure to set `q = 0.5` so that we are estimating the theoritical median.  Extract the coefficients into a variable named `res2_coefs`.  Finally print the `summary()` of the model. \n",
    "\n",
    "\n",
    "Documentation: https://www.statsmodels.org/dev/generated/statsmodels.regression.quantile_regression.QuantReg.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4731c2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const   -0.005388\n",
      "R        0.181800\n",
      "dtype: float64\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     Dp   R-squared:                       0.018\n",
      "Model:                            OLS   Adj. R-squared:                  0.009\n",
      "Method:                 Least Squares   F-statistic:                     1.954\n",
      "Date:                Wed, 02 Aug 2023   Prob (F-statistic):              0.165\n",
      "Time:                        20:18:11   Log-Likelihood:                 274.44\n",
      "No. Observations:                 107   AIC:                            -544.9\n",
      "Df Residuals:                     105   BIC:                            -539.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0031      0.008     -0.370      0.712      -0.020       0.014\n",
      "R              0.1545      0.111      1.398      0.165      -0.065       0.374\n",
      "==============================================================================\n",
      "Omnibus:                       11.018   Durbin-Watson:                   2.552\n",
      "Prob(Omnibus):                  0.004   Jarque-Bera (JB):                3.844\n",
      "Skew:                          -0.050   Prob(JB):                        0.146\n",
      "Kurtosis:                       2.077   Cond. No.                         61.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_QR = sm.regression.quantile_regression.QuantReg(y, x)\n",
    "\n",
    "results_QR = model_QR.fit(q=0.5)\n",
    "res2_coefs = results_QR.params\n",
    "\n",
    "print(res2_coefs)\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d47d5",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "Part 1: Use the `type()` method to determine the type of `res1_coefs` and `res2_coefs`. Print the type in a Jupyter cell. \n",
    "\n",
    "Part 2: In the next Jupyter cell show that `res1_coefs > res2_coefs`. What does the error mean? To resolve this error we must convert the data to an unnamed object or change the names of the objects. Since we are not focusing on pandas this week we will simply convert to a different data type.\n",
    "\n",
    "Part 3: Now, do the same comparision using the `tolist()` function at the end of each object name. \n",
    "\n",
    "Part 4: We performed two types of linear regression and compared their coefficients. Coefficients are essentially the rate at which x changes the values of y. Do some research on what OLS estimates versus what quantreg estimates and explain why we have two different coefficient estimates. In which cases do you think quantile regression will be useful? What about ordinary least squares regression? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "554fbe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(res1_coefs))\n",
    "print(type(res2_coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af56f11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const     True\n",
       "R        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1_coefs > res2_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ab710de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "res1_coefs.tolist()\n",
    "\n",
    "res2_coefs.tolist()\n",
    "\n",
    "print(res1_coefs[0]>res2_coefs[0])\n",
    "\n",
    "print(res1_coefs[1]>res2_coefs[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60212b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "477ce20b",
   "metadata": {},
   "source": [
    "The main difference between OLS and Quantile regression is the dependent value they are approximating. OLS approximates the mean of the dependent values based on the independent value; whereas Quantile regression will approximate any quantile(often the median) of the dependent value based on the independent value. Mean and median are not necessarily equal, the mean is more heavily swayed by extreme values; therefore, it is often important to consider both measures of central tendency to create a more accurate portryal of the data.\n",
    "\n",
    "The confidence interval surrounding an OLS approximation remains constant along the length of the line. Where as a the width of the confidence interval for QR can change as the spread in the dependent values changes. This can more accurately refelct the data in cases where the spread is not consistent. OLS models assume the errors in the data are normally distributed with constant variation, this is not the case in many data sets and is not required by QR.\n",
    "\n",
    "QR is then useful in cases where the errors do not meet the requirements for OLS or where extreme values may be effecting the data. QR is also useful in that it does not have to approximate the mean. For example, instead QR can create a function that looks at predciting the 90 percentile in the dependent data based on the independent variable. This may be useful in certain applications such as salary, spending, or costs. It is often useful to consider the bottom 90% (or equaivalently the top 10%) in these applications.\n",
    "\n",
    "For data that whose errors are normal and consistently spread in which the mean value is desired. Many data fall into the catergory of having normal errors and often the average value that coccurs is the one we are looking for. For example, height verses weight distribution tends to be normal when looking at segments of the population. \n",
    "\n",
    "(source: https://support.sas.com/resources/papers/proceedings16/5620-2016.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ac1049",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

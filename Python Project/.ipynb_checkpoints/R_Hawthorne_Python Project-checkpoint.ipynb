{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c930ed3",
   "metadata": {},
   "source": [
    "Read in libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00528dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba09da",
   "metadata": {},
   "source": [
    "Functions that I made/found/edited to make my life easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013f4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stats_df_creator (df, grouping, column):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe of data\n",
    "    grouping : column to group by\n",
    "    column : column we want stats on\n",
    "    Returns df with mean, median and third quantile values for column\n",
    "    '''\n",
    "    stats_df = df.groupby([grouping]).agg(\n",
    "        median=(column , np.median),\n",
    "        mean = (column, np.mean),\n",
    "        third_quantile = ( column, lambda x: np.percentile(x, q=75))       \n",
    "        )\n",
    "    return stats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed915862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_countries(index_phrase, df):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    index_phrase : phrase decribing the current index that I am printing\n",
    "    df : df that top 5 countries of that index are in\n",
    "    prints the countries for the top 5 scaled index\n",
    "    '''\n",
    "    print('The 5 countries in which salary goes the farthest on the ' +str(index_phrase) + ' index are:\\n')\n",
    "\n",
    "    for idx, country_code in enumerate(df['employee_residence']):\n",
    "        for key, value in country_code_dict.items():\n",
    "            if country_code == value:\n",
    "                print(key)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c4985ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_currency(amount, from_currency):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    amount : amount of money to be converted\n",
    "    from_currency: currency to be converted from\n",
    "    Returns currency is USD\n",
    "    '''\n",
    "    response = requests.get(\"https://v6.exchangerate-api.com/v6/45ab531ce52b1a50df0c239b/latest/USD\")\n",
    "    data = response.json()\n",
    "\n",
    "    if 'conversion_rates' in data:\n",
    "        rates = data['conversion_rates']\n",
    "        if from_currency == '':\n",
    "            return amount\n",
    "\n",
    "        if from_currency in rates :\n",
    "            converted_amount = amount / rates[from_currency]\n",
    "            return converted_amount\n",
    "        else:\n",
    "            raise ValueError(\"Invalid currency!\")\n",
    "    else:\n",
    "        raise ValueError(\"Unable to fetch exchange rates!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b84226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cities(index_phrase, df):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    index_phrase : phrase decribing the current index that I am printing\n",
    "    df : df that top 5 citiess of that index are in\n",
    "    prints the cities for the top 5 scaled index\n",
    "    '''\n",
    "    print('The 5 cities in which salary goes the farthest on the ' +str(index_phrase) + ' index are:')\n",
    "\n",
    "    for idx, city in enumerate(df['City']):\n",
    "        print(city)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f7b70",
   "metadata": {},
   "source": [
    "Read in all the data files, including the currency codes I got from https://www.exchangerate-api.com/docs/supported-currencies . \n",
    "\n",
    "Then remove parenthesis from the country codes df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70966451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\2988162007.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  country_codes_df['Country'] = country_codes_df['Country'].str.replace('\\(.*\\)','')\n"
     ]
    }
   ],
   "source": [
    "cost_of_living_df = pd.read_csv('cost_of_living.csv')\n",
    "country_codes_df = pd.read_excel('country_codes.xlsx', engine='openpyxl')\n",
    "ds_salaries_df = pd.read_csv('ds_salaries.csv')\n",
    "levels_fyi_salary_data_df = pd.read_csv('Levels_Fyi_Salary_Data.csv')\n",
    "currency_codes = pd.read_csv('currency_codes.csv')\n",
    "\n",
    "#removning the () from the country names\n",
    "country_codes_df['Country'] = country_codes_df['Country'].str.replace('\\(.*\\)','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0bc14c",
   "metadata": {},
   "source": [
    "Convert currency codes df and country codes  to dictionaries to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0e7e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Function to return a default\n",
    "# values for keys that is not\n",
    "# present\n",
    "def def_value():\n",
    "    return \"Not Present\"\n",
    "\n",
    "country_code_dict = defaultdict(def_value, zip(country_codes_df['Country'], country_codes_df['Alpha-2 code']))\n",
    "\n",
    "currency_codes_dict= defaultdict(def_value, zip(currency_codes['Country'], currency_codes['Currency Code']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e7c8b",
   "metadata": {},
   "source": [
    "Start editing salary data:\n",
    "\n",
    "Get just data science salaries for entry level (less then 4 years of expereince), fulltime employes from Levels_fyi_slary_data_df and ds_salaries_df\n",
    "\n",
    "Then return columns with salary date, location, and salary\n",
    "\n",
    "Reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dd22d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  totalyearlycompensation           location\n",
      "0  6/17/2018 19:02:50                   200000        Seattle, WA\n",
      "1  6/21/2018 10:54:35                   600000      Los Gatos, CA\n",
      "2  8/15/2018 11:57:44                   120000     Washington, DC\n",
      "3  8/15/2018 15:38:02                   220000        Redmond, WA\n",
      "4  8/15/2018 20:38:36                   147000  San Francisco, CA\n",
      "   work_year  salary_in_usd employee_residence\n",
      "0       2020          51321                 FR\n",
      "1       2020          39916                 FR\n",
      "2       2020          62726                 DE\n",
      "3       2020          49268                 DE\n",
      "4       2020         105000                 US\n"
     ]
    }
   ],
   "source": [
    "data_science_levels_fyi_salary_data_df = levels_fyi_salary_data_df.loc[(levels_fyi_salary_data_df[\"title\"] =='Data Scientist')\n",
    "                              &(levels_fyi_salary_data_df[\"yearsofexperience\"] < 4),\n",
    "                              ['timestamp','totalyearlycompensation', 'location']]\n",
    "\n",
    "\n",
    "\n",
    "data_science_ds_salaries_df = ds_salaries_df.loc[(ds_salaries_df['job_title'] == 'Data Scientist') \n",
    "                   & (ds_salaries_df['employment_type'] == 'FT') \n",
    "                   & (ds_salaries_df['experience_level'] == 'EN'), \n",
    "                   ['work_year' , 'salary_in_usd' , 'employee_residence']]\n",
    "\n",
    "data_science_ds_salaries_df = data_science_ds_salaries_df.reset_index(drop=True)\n",
    "\n",
    "data_science_levels_fyi_salary_data_df = data_science_levels_fyi_salary_data_df.reset_index(drop=True)\n",
    "\n",
    "print(data_science_levels_fyi_salary_data_df.head())\n",
    "print(data_science_ds_salaries_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9a8ba",
   "metadata": {},
   "source": [
    "cleaning data:\n",
    "    For data_science_levels_fyi_salary_data_df\n",
    "    Create work_year column\n",
    "    \n",
    "    Break location into city, state and country; then add country code    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf080fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3070310417.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['country'][idx] = 'United States'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "            timestamp  totalyearlycompensation           location  work_year  \\\n",
      "0  6/17/2018 19:02:50                   200000        Seattle, WA       2018   \n",
      "1  6/21/2018 10:54:35                   600000      Los Gatos, CA       2018   \n",
      "2  8/15/2018 11:57:44                   120000     Washington, DC       2018   \n",
      "3  8/15/2018 15:38:02                   220000        Redmond, WA       2018   \n",
      "4  8/15/2018 20:38:36                   147000  San Francisco, CA       2018   \n",
      "\n",
      "            city state        country  \n",
      "0        Seattle    WA  United States  \n",
      "1      Los Gatos    CA  United States  \n",
      "2     Washington    DC  United States  \n",
      "3        Redmond    WA  United States  \n",
      "4  San Francisco    CA  United States  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3070310417.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['country'][161] = 'Israel'\n"
     ]
    }
   ],
   "source": [
    "data_science_levels_fyi_salary_data_df.dtypes\n",
    "\n",
    "data_science_levels_fyi_salary_data_df['work_year'] = pd.to_datetime(data_science_levels_fyi_salary_data_df['timestamp'] , format='%m/%d/%Y %H:%M:%S').dt.year\n",
    "\n",
    "data_science_levels_fyi_salary_data_df[['city','state','country']] = data_science_levels_fyi_salary_data_df[\"location\"].str.split(', ',expand=True)\n",
    "\n",
    " \n",
    "#####add country for those locations that only had city and state\n",
    "\n",
    "for idx, value in enumerate (data_science_levels_fyi_salary_data_df['state']):  \n",
    "    if (len(value) == 2) & (data_science_levels_fyi_salary_data_df['country'][idx] == None):\n",
    "        data_science_levels_fyi_salary_data_df['country'][idx] = 'United States'\n",
    "    elif data_science_levels_fyi_salary_data_df['country'][idx] == None:\n",
    "        print(idx)\n",
    "    \n",
    "###only printed index of 161 which correlates to Israel\n",
    "data_science_levels_fyi_salary_data_df['country'][161] = 'Israel' \n",
    "\n",
    "print(data_science_levels_fyi_salary_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef4f49b",
   "metadata": {},
   "source": [
    "Add currency code for currency conversion from the currency code dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61cfab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3301572926.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['currency_code'][idx] = [val for key, val in currency_codes_dict.items() if re.search(value, key)]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3301572926.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['employee_residence'][idx] = [val for key, val in country_code_dict.items() if value in key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  totalyearlycompensation           location  work_year  \\\n",
      "0  6/17/2018 19:02:50                   200000        Seattle, WA       2018   \n",
      "1  6/21/2018 10:54:35                   600000      Los Gatos, CA       2018   \n",
      "2  8/15/2018 11:57:44                   120000     Washington, DC       2018   \n",
      "3  8/15/2018 15:38:02                   220000        Redmond, WA       2018   \n",
      "4  8/15/2018 20:38:36                   147000  San Francisco, CA       2018   \n",
      "\n",
      "            city state        country currency_code employee_residence  \n",
      "0        Seattle    WA  United States         [USD]           [UM, US]  \n",
      "1      Los Gatos    CA  United States         [USD]           [UM, US]  \n",
      "2     Washington    DC  United States         [USD]           [UM, US]  \n",
      "3        Redmond    WA  United States         [USD]           [UM, US]  \n",
      "4  San Francisco    CA  United States         [USD]           [UM, US]  \n"
     ]
    }
   ],
   "source": [
    "data_science_levels_fyi_salary_data_df['currency_code']=''\n",
    "data_science_levels_fyi_salary_data_df['employee_residence']=''\n",
    "\n",
    "for idx, value in enumerate (data_science_levels_fyi_salary_data_df['country']):\n",
    "    data_science_levels_fyi_salary_data_df['currency_code'][idx] = [val for key, val in currency_codes_dict.items() if re.search(value, key)]\n",
    "    data_science_levels_fyi_salary_data_df['employee_residence'][idx] = [val for key, val in country_code_dict.items() if value in key]\n",
    "\n",
    "print(data_science_levels_fyi_salary_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42143d",
   "metadata": {},
   "source": [
    "I don't know why Hong Kong won't work so I fixed that here. Also fixed countries that got two codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0179640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  totalyearlycompensation           location  work_year  \\\n",
      "0  6/17/2018 19:02:50                   200000        Seattle, WA       2018   \n",
      "1  6/21/2018 10:54:35                   600000      Los Gatos, CA       2018   \n",
      "2  8/15/2018 11:57:44                   120000     Washington, DC       2018   \n",
      "3  8/15/2018 15:38:02                   220000        Redmond, WA       2018   \n",
      "4  8/15/2018 20:38:36                   147000  San Francisco, CA       2018   \n",
      "\n",
      "            city state        country currency_code employee_residence  \n",
      "0        Seattle    WA  United States         [USD]               [US]  \n",
      "1      Los Gatos    CA  United States         [USD]               [US]  \n",
      "2     Washington    DC  United States         [USD]               [US]  \n",
      "3        Redmond    WA  United States         [USD]               [US]  \n",
      "4  San Francisco    CA  United States         [USD]               [US]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\1514313522.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['currency_code'][idx] = [\"HKD\"]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\1514313522.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['employee_residence'][idx] = ['HK']\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\1514313522.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['employee_residence'][idx] = ['US']\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\1514313522.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['employee_residence'][idx] = ['IN']\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\1514313522.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['employee_residence'][idx] = ['IE']\n"
     ]
    }
   ],
   "source": [
    "for idx, value in enumerate (data_science_levels_fyi_salary_data_df['country']):\n",
    "    if value == 'Hong Kong (SAR)':\n",
    "        data_science_levels_fyi_salary_data_df['currency_code'][idx] = [\"HKD\"]\n",
    "        data_science_levels_fyi_salary_data_df['employee_residence'][idx] = ['HK']\n",
    "\n",
    "for idx, value in enumerate (data_science_levels_fyi_salary_data_df['country']):\n",
    "    if value == \"United States\":\n",
    "        data_science_levels_fyi_salary_data_df['employee_residence'][idx] = ['US']\n",
    "    if value == \"India\":\n",
    "        data_science_levels_fyi_salary_data_df['employee_residence'][idx] = ['IN']\n",
    "    if value == \"Ireland\":\n",
    "        data_science_levels_fyi_salary_data_df['employee_residence'][idx] = ['IE']\n",
    "\n",
    "        \n",
    "print(data_science_levels_fyi_salary_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049a820",
   "metadata": {},
   "source": [
    "Convert all currancey to US currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81779d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3728537373.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['salary_in_usd'][idx]=value\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3728537373.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df['salary_in_usd'][idx] = convert_currency(value, data_science_levels_fyi_salary_data_df['currency_code'][idx][0] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  totalyearlycompensation           location  work_year  \\\n",
      "0  6/17/2018 19:02:50                   200000        Seattle, WA       2018   \n",
      "1  6/21/2018 10:54:35                   600000      Los Gatos, CA       2018   \n",
      "2  8/15/2018 11:57:44                   120000     Washington, DC       2018   \n",
      "3  8/15/2018 15:38:02                   220000        Redmond, WA       2018   \n",
      "4  8/15/2018 20:38:36                   147000  San Francisco, CA       2018   \n",
      "\n",
      "            city state        country currency_code employee_residence  \\\n",
      "0        Seattle    WA  United States         [USD]               [US]   \n",
      "1      Los Gatos    CA  United States         [USD]               [US]   \n",
      "2     Washington    DC  United States         [USD]               [US]   \n",
      "3        Redmond    WA  United States         [USD]               [US]   \n",
      "4  San Francisco    CA  United States         [USD]               [US]   \n",
      "\n",
      "  salary_in_usd  \n",
      "0        200000  \n",
      "1        600000  \n",
      "2        120000  \n",
      "3        220000  \n",
      "4        147000  \n"
     ]
    }
   ],
   "source": [
    "data_science_levels_fyi_salary_data_df['salary_in_usd']=''\n",
    "\n",
    "\n",
    "for idx, value in enumerate (data_science_levels_fyi_salary_data_df['totalyearlycompensation']): \n",
    "    if (data_science_levels_fyi_salary_data_df['currency_code'][idx] != [\"USD\"]):\n",
    "        data_science_levels_fyi_salary_data_df['salary_in_usd'][idx] = convert_currency(value, data_science_levels_fyi_salary_data_df['currency_code'][idx][0] )\n",
    "    else:\n",
    "        data_science_levels_fyi_salary_data_df['salary_in_usd'][idx]=value  \n",
    "\n",
    "        \n",
    "print(data_science_levels_fyi_salary_data_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b20806",
   "metadata": {},
   "source": [
    "Make copies to merge without extra columns and then merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27fc205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   work_year          city state        country employee_residence  \\\n",
      "0       2018       Seattle    WA  United States                 US   \n",
      "1       2018     Los Gatos    CA  United States                 US   \n",
      "2       2018    Washington    DC  United States                 US   \n",
      "3       2018  Santa Monica    CA  United States                 US   \n",
      "4       2018       Redmond    WA  United States                 US   \n",
      "\n",
      "  salary_in_usd  \n",
      "0      200000.0  \n",
      "1      600000.0  \n",
      "2      120000.0  \n",
      "3      120000.0  \n",
      "4      220000.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\1026206038.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_science_levels_fyi_salary_data_df_merge['employee_residence'][idx]= value[0]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\1026206038.py:7: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  salary_df = pd.merge(data_science_levels_fyi_salary_data_df_merge, data_science_ds_salaries_df, how = 'outer')\n"
     ]
    }
   ],
   "source": [
    "data_science_levels_fyi_salary_data_df_merge = data_science_levels_fyi_salary_data_df.drop(['timestamp','totalyearlycompensation','location','currency_code'],axis=1)\n",
    "\n",
    "for idx, value in enumerate(data_science_levels_fyi_salary_data_df_merge['employee_residence']):\n",
    "    data_science_levels_fyi_salary_data_df_merge['employee_residence'][idx]= value[0]\n",
    "    \n",
    "\n",
    "salary_df = pd.merge(data_science_levels_fyi_salary_data_df_merge, data_science_ds_salaries_df, how = 'outer')\n",
    "\n",
    "print(salary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7554e6d",
   "metadata": {},
   "source": [
    "Change money to 2023 dollars using SSA AWI values. \n",
    "Increase from:\n",
    "2018 to 2019: 3.75%\n",
    "2019 to 2021: 2.83%\n",
    "2020 to 2021: 8.89%\n",
    "2021 to 2022: 4.8%\n",
    "2022 to 2023: 4.2%\n",
    "source: \n",
    "https://www.ssa.gov/oact/TR/TRassum.html and \n",
    "https://www.ssa.gov/oact/cola/awidevelop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a69327d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   work_year          city state        country employee_residence  \\\n",
      "0       2018       Seattle    WA  United States                 US   \n",
      "1       2018     Los Gatos    CA  United States                 US   \n",
      "2       2018    Washington    DC  United States                 US   \n",
      "3       2018  Santa Monica    CA  United States                 US   \n",
      "4       2018       Redmond    WA  United States                 US   \n",
      "\n",
      "  salary_in_usd salary_in_2023  \n",
      "0      200000.0  253743.437031  \n",
      "1      600000.0  761230.311093  \n",
      "2      120000.0  152246.062219  \n",
      "3      120000.0  152246.062219  \n",
      "4      220000.0  279117.780734  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\49291514.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_df['salary_in_2023'][idx] = salary_df['salary_in_usd'][idx]*1.0375*1.0283*1.089*1.048*1.042\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\49291514.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_df['salary_in_2023'][idx] = salary_df['salary_in_usd'][idx]*1.0283*1.089*1.048*1.042\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\49291514.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_df['salary_in_2023'][idx] = salary_df['salary_in_usd'][idx]*1.089*1.048*1.042\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\49291514.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_df['salary_in_2023'][idx] = salary_df['salary_in_usd'][idx]*1.048*1.042\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\49291514.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_df['salary_in_2023'][idx] = salary_df['salary_in_usd'][idx]*1.042\n"
     ]
    }
   ],
   "source": [
    "salary_df['salary_in_2023']=''\n",
    "\n",
    "for idx, value in enumerate(salary_df['work_year']):\n",
    "    if value == 2018:\n",
    "        salary_df['salary_in_2023'][idx] = salary_df['salary_in_usd'][idx]*1.0375*1.0283*1.089*1.048*1.042\n",
    "    if value == 2019:\n",
    "        salary_df['salary_in_2023'][idx] = salary_df['salary_in_usd'][idx]*1.0283*1.089*1.048*1.042\n",
    "    if value == 2020:\n",
    "        salary_df['salary_in_2023'][idx] = salary_df['salary_in_usd'][idx]*1.089*1.048*1.042\n",
    "    if value == 2021:\n",
    "        salary_df['salary_in_2023'][idx] = salary_df['salary_in_usd'][idx]*1.048*1.042\n",
    "    if value == 2022:\n",
    "        salary_df['salary_in_2023'][idx] = salary_df['salary_in_usd'][idx]*1.042\n",
    "print(salary_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a161a",
   "metadata": {},
   "source": [
    "Manipulating cost of living data. Sense we don't have data for most cities outside the US, I am planning to look at all data overall grouped by country. Then look more specifically at the US.\n",
    "\n",
    "To do this I first am breaking apart the \"City\" column in the cost of living data into city, state and country.\n",
    "\n",
    "2-digit country codes are then added to align with the salary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e982cd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                 City  Cost of Living Index  Rent Index  \\\n",
      "0   NaN    Hamilton, Bermuda                149.02       96.10   \n",
      "1   NaN  Zurich, Switzerland                131.24       69.26   \n",
      "2   NaN   Basel, Switzerland                130.93       49.38   \n",
      "3   NaN     Zug, Switzerland                128.13       72.12   \n",
      "4   NaN  Lugano, Switzerland                123.99       44.99   \n",
      "\n",
      "   Cost of Living Plus Rent Index  Groceries Index  Restaurant Price Index  \\\n",
      "0                          124.22           157.89                  155.22   \n",
      "1                          102.19           136.14                  132.52   \n",
      "2                           92.70           137.07                  130.95   \n",
      "3                          101.87           132.61                  130.93   \n",
      "4                           86.96           129.17                  119.80   \n",
      "\n",
      "   Local Purchasing Power Index      city        state      country  \\\n",
      "0                         79.43  Hamilton      Bermuda      Bermuda   \n",
      "1                        129.79    Zurich  Switzerland  Switzerland   \n",
      "2                        111.53     Basel  Switzerland  Switzerland   \n",
      "3                        143.40       Zug  Switzerland  Switzerland   \n",
      "4                        111.96    Lugano  Switzerland  Switzerland   \n",
      "\n",
      "  employee_residence  \n",
      "0               [BM]  \n",
      "1               [CH]  \n",
      "2               [CH]  \n",
      "3               [CH]  \n",
      "4               [CH]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3238637228.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_of_living_df['country'][idx] = cost_of_living_df['state'][idx]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3238637228.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_of_living_df['employee_residence'][idx] = [val for key, val in country_code_dict.items() if value in key]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3238637228.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_of_living_df['employee_residence'][idx] = ['US']\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3238637228.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_of_living_df['employee_residence'][idx] = ['IE']\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3238637228.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_of_living_df['employee_residence'][idx] = ['IN']\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\3238637228.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_of_living_df['employee_residence'][idx] = ['GE']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cost_of_living_df[['city','state','country']] = cost_of_living_df[\"City\"].str.split(', ',expand=True)\n",
    "cost_of_living_df['employee_residence']=''\n",
    "\n",
    "\n",
    "for idx, value in enumerate (cost_of_living_df['state']):  \n",
    "    if (cost_of_living_df['country'][idx] == None):\n",
    "        cost_of_living_df['country'][idx] = cost_of_living_df['state'][idx]\n",
    "\n",
    "for idx, value in enumerate (cost_of_living_df['country']): \n",
    "    cost_of_living_df['employee_residence'][idx] = [val for key, val in country_code_dict.items() if value in key]\n",
    "\n",
    "    \n",
    "#the following pulled two keys from the dictionary\n",
    "for idx, value in enumerate (cost_of_living_df['country']):\n",
    "    if value == \"United States\":\n",
    "        cost_of_living_df['employee_residence'][idx] = ['US']\n",
    "    if value == \"India\":\n",
    "        cost_of_living_df['employee_residence'][idx] = ['IN']\n",
    "    if value == \"Ireland\":\n",
    "        cost_of_living_df['employee_residence'][idx] = ['IE']\n",
    "    if value == \"Georgia\":\n",
    "        cost_of_living_df['employee_residence'][idx] = ['GE']\n",
    "print(cost_of_living_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e053d6a",
   "metadata": {},
   "source": [
    " replace unknown country code with none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fed0800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\73360534.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_of_living_df['employee_residence'][idx]= value[0]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\73360534.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cost_of_living_df['employee_residence'][idx] = None\n"
     ]
    }
   ],
   "source": [
    "for idx, value in enumerate(cost_of_living_df['employee_residence']):\n",
    "    if (len(cost_of_living_df['employee_residence'][idx]) == 1):\n",
    "        cost_of_living_df['employee_residence'][idx]= value[0]\n",
    "    else:\n",
    "        cost_of_living_df['employee_residence'][idx] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34726377",
   "metadata": {},
   "source": [
    "get stats for each of the five indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02893f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    median    mean  third_quantile\n",
      "employee_residence                                \n",
      "AE                  55.235  55.955         59.4975\n",
      "AF                  21.350  21.350         21.3500\n",
      "AL                  38.680  38.680         38.6800\n",
      "AM                  34.010  34.010         34.0100\n",
      "AR                  35.250  35.250         35.2500\n",
      "                    median     mean  third_quantile\n",
      "employee_residence                                 \n",
      "AE                  49.045  54.4525         63.4575\n",
      "AF                   3.170   3.1700          3.1700\n",
      "AL                  11.330  11.3300         11.3300\n",
      "AM                  11.890  11.8900         11.8900\n",
      "AR                  10.730  10.7300         10.7300\n",
      "                    median   mean  third_quantile\n",
      "employee_residence                               \n",
      "AE                  53.095  55.25           59.57\n",
      "AF                  12.830  12.83           12.83\n",
      "AL                  25.860  25.86           25.86\n",
      "AM                  23.640  23.64           23.64\n",
      "AR                  23.750  23.75           23.75\n",
      "                    median     mean  third_quantile\n",
      "employee_residence                                 \n",
      "AE                  44.625  44.3725         48.6275\n",
      "AF                  15.220  15.2200         15.2200\n",
      "AL                  30.990  30.9900         30.9900\n",
      "AM                  27.810  27.8100         27.8100\n",
      "AR                  28.540  28.5400         28.5400\n",
      "                    median     mean  third_quantile\n",
      "employee_residence                                 \n",
      "AE                   59.03  56.3875         62.3525\n",
      "AF                   14.85  14.8500         14.8500\n",
      "AL                   29.86  29.8600         29.8600\n",
      "AM                   31.01  31.0100         31.0100\n",
      "AR                   34.35  34.3500         34.3500\n"
     ]
    }
   ],
   "source": [
    "stat_for_cost_of_living = stats_df_creator( cost_of_living_df, \n",
    "                                           'employee_residence',\n",
    "                                           'Cost of Living Index')\n",
    "\n",
    "stat_for_rent_index = stats_df_creator( cost_of_living_df, \n",
    "                                           'employee_residence',\n",
    "                                           'Rent Index')\n",
    "stat_for_cost_of_living_plus_rent_index = stats_df_creator( cost_of_living_df, \n",
    "                                           'employee_residence',\n",
    "                                           'Cost of Living Plus Rent Index')\n",
    "stat_for_groceries_index = stats_df_creator( cost_of_living_df, \n",
    "                                           'employee_residence',\n",
    "                                           'Groceries Index')\n",
    "stat_for_restaurant_price_index = stats_df_creator( cost_of_living_df, \n",
    "                                           'employee_residence',\n",
    "                                           'Restaurant Price Index')\n",
    "\n",
    "print(stat_for_cost_of_living.head())\n",
    "print(stat_for_rent_index.head())\n",
    "print(stat_for_cost_of_living_plus_rent_index.head())\n",
    "print(stat_for_groceries_index.head())\n",
    "print(stat_for_restaurant_price_index.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a131f",
   "metadata": {},
   "source": [
    "I reviewed all the stats above and found that the values were very close to \n",
    "eachother for all three statistics. This implies a very low spread. I've decided\n",
    "to focus on the median as the measure to use for the indices\n",
    "\n",
    "To that end the next step is to create a df of just these stats then turn it into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aff2952",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_median_index_df = stat_for_cost_of_living.drop(['mean','third_quantile'],axis=1)\n",
    "stat_median_index_df = stat_median_index_df.rename(columns={\"median\": \"cost_of_living\"})\n",
    "stat_median_index_df['rent_index'] = stat_for_rent_index['median']\n",
    "stat_median_index_df['cost_of_living_plus_rent_index'] = stat_for_cost_of_living_plus_rent_index['median']\n",
    "stat_median_index_df['groceries_index'] = stat_for_groceries_index['median']\n",
    "stat_median_index_df['restuarant_price_index'] = stat_for_restaurant_price_index['median']\n",
    "stat_median_index_df.reset_index(inplace=True)\n",
    "\n",
    "index_dict =  defaultdict(def_value,   [(i,[v,w,x,y,z ]) \n",
    "                                        for i, v,w,x,y,z \n",
    "                                        in zip(stat_median_index_df.employee_residence, \n",
    "                                                                stat_median_index_df.cost_of_living, \n",
    "                                                                stat_median_index_df.rent_index,\n",
    "                                                                stat_median_index_df.cost_of_living_plus_rent_index,\n",
    "                                                                stat_median_index_df.groceries_index,\n",
    "                                                                stat_median_index_df.restuarant_price_index) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c46bd",
   "metadata": {},
   "source": [
    "Group Salaries by employee_residence(country) and calculate the 25th, median(50th) and 75 quantiles.\n",
    "\n",
    "Reset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69f7fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee_residence  first_quantile         median  third_quantile\n",
      "0                 AE    44951.965027   44951.965027    44951.965027\n",
      "1                 AT    20062.569140   20062.569140    20062.569140\n",
      "2                 AU    57804.204508   65210.900679    77777.713339\n",
      "3                 CA    68329.183659   78787.568122    90223.785407\n",
      "4                 CH   134427.421658  138231.717691   169114.387210\n"
     ]
    }
   ],
   "source": [
    "salary_percentile_df = salary_df.groupby(['employee_residence']).agg(\n",
    "    first_quantile = ('salary_in_2023' , lambda x: np.percentile(x, q=25)),\n",
    "    median = ('salary_in_2023' , lambda x: np.percentile(x, q=50)),                  \n",
    "    third_quantile = ('salary_in_2023' , lambda x: np.percentile(x, q=75))       \n",
    "    )\n",
    "\n",
    "salary_percentile_df.reset_index(inplace=True)\n",
    "\n",
    "print(salary_percentile_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b97906e",
   "metadata": {},
   "source": [
    "Get values from index_dict for the countries we have salary and index data for.\n",
    "\n",
    "There is no cost of living data for vietnam, but there was salary so I removed this from my data set.\n",
    "\n",
    "Then scale each salary measure by each \"cost of\" index, then convert values to numeric.\n",
    "\n",
    "The largest of these values indicate were salary will go the farthest in each catergory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38f20f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee_residence  first_quantile         median  third_quantile  \\\n",
      "0                 AE    44951.965027   44951.965027    44951.965027   \n",
      "1                 AT    20062.569140   20062.569140    20062.569140   \n",
      "2                 AU    57804.204508   65210.900679    77777.713339   \n",
      "3                 CA    68329.183659   78787.568122    90223.785407   \n",
      "4                 CH   134427.421658  138231.717691   169114.387210   \n",
      "\n",
      "                                      cost_of_values  \\\n",
      "0            [55.235, 49.045, 53.095, 44.625, 59.03]   \n",
      "1                [73.55, 30.14, 52.54, 66.99, 68.46]   \n",
      "2  [76.67500000000001, 37.595, 58.945, 77.295, 74...   \n",
      "3  [71.7, 34.955, 54.769999999999996, 69.985, 70....   \n",
      "4             [123.99, 59.55, 92.74, 129.17, 127.01]   \n",
      "\n",
      "   cost_of_living_scaled_q1  rent_index_scaled_q1  \\\n",
      "0              81383.117638          91654.531608   \n",
      "1              27277.456342          66564.595686   \n",
      "2              75388.594076         153755.032606   \n",
      "3              95298.721979         195477.567326   \n",
      "4             108417.954398         225738.743339   \n",
      "\n",
      "   cost_of_living_plus_rent_index_scaled_q1  groceries_index_scaled_q1  \\\n",
      "0                              84663.273429              100732.694739   \n",
      "1                              38185.323829               29948.602985   \n",
      "2                              98064.644174               74783.885773   \n",
      "3                             124756.588751               97634.041093   \n",
      "4                             144950.853632              104070.156893   \n",
      "\n",
      "   restuarant_price_index_q1  cost_of_living_scaled_median  \\\n",
      "0               76151.050359                  81383.117638   \n",
      "1               29305.534823                  27277.456342   \n",
      "2               77955.771420                  85048.452141   \n",
      "3               96585.177269                 109885.032249   \n",
      "4              105840.029650                 111486.182508   \n",
      "\n",
      "   rent_index_scaled_median  cost_of_living_plus_rent_index_scaled_median  \\\n",
      "0              91654.531608                                  84663.273429   \n",
      "1              66564.595686                                  38185.323829   \n",
      "2             173456.312485                                 110630.080039   \n",
      "3             225397.133807                                 143851.685452   \n",
      "4             232127.149775                                 149052.962790   \n",
      "\n",
      "   groceries_index_scaled_median  restuarant_price_index_median  \\\n",
      "0                  100732.694739                   76151.050359   \n",
      "1                   29948.602985                   29305.534823   \n",
      "2                   84366.260015                   87944.572729   \n",
      "3                  112577.792559                  111368.390872   \n",
      "4                  107015.342333                  108835.302489   \n",
      "\n",
      "   cost_of_living_scaled_q3  rent_index_scaled_q3  \\\n",
      "0              81383.117638          91654.531608   \n",
      "1              27277.456342          66564.595686   \n",
      "2             101438.165425         206883.131638   \n",
      "3             125835.126091         258114.105013   \n",
      "4             136393.569812         283987.216138   \n",
      "\n",
      "   cost_of_living_plus_rent_index_scaled_q3  groceries_index_scaled_q3  \\\n",
      "0                              84663.273429              100732.694739   \n",
      "1                              38185.323829               29948.602985   \n",
      "2                             131949.636677              100624.507846   \n",
      "3                             164732.125995              128918.747456   \n",
      "4                             182353.231842              130923.888836   \n",
      "\n",
      "   restuarant_price_index_q3  \n",
      "0               76151.050359  \n",
      "1               29305.534823  \n",
      "2              104892.398300  \n",
      "3              127533.798017  \n",
      "4              133150.450524  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['cost_of_values'][idx] = index_dict.get(salary_percentile_df['employee_residence'][idx])\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['cost_of_living_scaled_q3'][idx] =salary*100/salary_percentile_df['cost_of_values'][idx][0]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['rent_index_scaled_q3'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][1]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['cost_of_living_plus_rent_index_scaled_q3'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][2]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['groceries_index_scaled_q3'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][3]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['restuarant_price_index_q3'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][4]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['cost_of_living_scaled_median'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][0]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['rent_index_scaled_median'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][1]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['cost_of_living_plus_rent_index_scaled_median'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][2]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['groceries_index_scaled_median'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][3]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['restuarant_price_index_median'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][4]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['cost_of_living_scaled_q1'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][0]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['rent_index_scaled_q1'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][1]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['cost_of_living_plus_rent_index_scaled_q1'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][2]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['groceries_index_scaled_q1'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][3]\n",
      "C:\\Users\\hawthorner\\AppData\\Local\\Temp\\ipykernel_22188\\773068333.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  salary_percentile_df['restuarant_price_index_q1'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][4]\n"
     ]
    }
   ],
   "source": [
    "index_vietnam =salary_percentile_df[salary_percentile_df['employee_residence'] == 'VN'].index\n",
    "salary_percentile_df.drop(index_vietnam , inplace=True)\n",
    "\n",
    "\n",
    "salary_percentile_df['cost_of_values']=''\n",
    "\n",
    "for idx, salary in enumerate(salary_percentile_df['third_quantile']):\n",
    "    salary_percentile_df['cost_of_values'][idx] = index_dict.get(salary_percentile_df['employee_residence'][idx])\n",
    "\n",
    "\n",
    "salary_percentile_df['cost_of_living_scaled_q1']=''\n",
    "salary_percentile_df['rent_index_scaled_q1']=''\n",
    "salary_percentile_df['cost_of_living_plus_rent_index_scaled_q1']=''\n",
    "salary_percentile_df['groceries_index_scaled_q1']=''\n",
    "salary_percentile_df['restuarant_price_index_q1']=''\n",
    "salary_percentile_df['cost_of_living_scaled_median']=''\n",
    "salary_percentile_df['rent_index_scaled_median']=''\n",
    "salary_percentile_df['cost_of_living_plus_rent_index_scaled_median']=''\n",
    "salary_percentile_df['groceries_index_scaled_median']=''\n",
    "salary_percentile_df['restuarant_price_index_median']='' \n",
    "salary_percentile_df['cost_of_living_scaled_q3']=''\n",
    "salary_percentile_df['rent_index_scaled_q3']=''\n",
    "salary_percentile_df['cost_of_living_plus_rent_index_scaled_q3']=''\n",
    "salary_percentile_df['groceries_index_scaled_q3']=''\n",
    "salary_percentile_df['restuarant_price_index_q3']=''     \n",
    "\n",
    "\n",
    "for idx, salary in enumerate(salary_percentile_df['third_quantile']):\n",
    "    salary_percentile_df['cost_of_living_scaled_q3'][idx] =salary*100/salary_percentile_df['cost_of_values'][idx][0]\n",
    "    salary_percentile_df['rent_index_scaled_q3'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][1]\n",
    "    salary_percentile_df['cost_of_living_plus_rent_index_scaled_q3'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][2]\n",
    "    salary_percentile_df['groceries_index_scaled_q3'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][3]\n",
    "    salary_percentile_df['restuarant_price_index_q3'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][4]\n",
    "    \n",
    "    \n",
    "for idx, salary in enumerate(salary_percentile_df['median']):    \n",
    "    salary_percentile_df['cost_of_living_scaled_median'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][0]\n",
    "    salary_percentile_df['rent_index_scaled_median'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][1]\n",
    "    salary_percentile_df['cost_of_living_plus_rent_index_scaled_median'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][2]\n",
    "    salary_percentile_df['groceries_index_scaled_median'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][3]\n",
    "    salary_percentile_df['restuarant_price_index_median'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][4]\n",
    "    \n",
    "for idx, salary in enumerate(salary_percentile_df['first_quantile']):   \n",
    "    salary_percentile_df['cost_of_living_scaled_q1'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][0]\n",
    "    salary_percentile_df['rent_index_scaled_q1'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][1]\n",
    "    salary_percentile_df['cost_of_living_plus_rent_index_scaled_q1'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][2]\n",
    "    salary_percentile_df['groceries_index_scaled_q1'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][3]\n",
    "    salary_percentile_df['restuarant_price_index_q1'][idx] = salary*100/salary_percentile_df['cost_of_values'][idx][4]\n",
    "    \n",
    "salary_percentile_df['cost_of_living_scaled_q1'] = pd.to_numeric(salary_percentile_df['cost_of_living_scaled_q1'], errors='coerce')\n",
    "salary_percentile_df['rent_index_scaled_q1'] = pd.to_numeric(salary_percentile_df['rent_index_scaled_q1'], errors='coerce')\n",
    "salary_percentile_df['cost_of_living_plus_rent_index_scaled_q1'] = pd.to_numeric(salary_percentile_df['cost_of_living_plus_rent_index_scaled_q1'], errors='coerce')\n",
    "salary_percentile_df['groceries_index_scaled_q1'] = pd.to_numeric(salary_percentile_df['groceries_index_scaled_q1'], errors='coerce')\n",
    "salary_percentile_df['restuarant_price_index_q1'] = pd.to_numeric(salary_percentile_df['restuarant_price_index_q1'], errors='coerce')\n",
    "\n",
    "\n",
    "salary_percentile_df['cost_of_living_scaled_median'] = pd.to_numeric(salary_percentile_df['cost_of_living_scaled_median'], errors='coerce')\n",
    "salary_percentile_df['rent_index_scaled_median'] = pd.to_numeric(salary_percentile_df['rent_index_scaled_median'], errors='coerce')\n",
    "salary_percentile_df['cost_of_living_plus_rent_index_scaled_median'] = pd.to_numeric(salary_percentile_df['cost_of_living_plus_rent_index_scaled_median'], errors='coerce')\n",
    "salary_percentile_df['groceries_index_scaled_median'] = pd.to_numeric(salary_percentile_df['groceries_index_scaled_median'], errors='coerce')\n",
    "salary_percentile_df['restuarant_price_index_median'] = pd.to_numeric(salary_percentile_df['restuarant_price_index_median'], errors='coerce')\n",
    "\n",
    "\n",
    "salary_percentile_df['cost_of_living_scaled_q3'] = pd.to_numeric(salary_percentile_df['cost_of_living_scaled_q3'], errors='coerce')\n",
    "salary_percentile_df['rent_index_scaled_q3'] = pd.to_numeric(salary_percentile_df['rent_index_scaled_q3'], errors='coerce')\n",
    "salary_percentile_df['cost_of_living_plus_rent_index_scaled_q3'] = pd.to_numeric(salary_percentile_df['cost_of_living_plus_rent_index_scaled_q3'], errors='coerce')\n",
    "salary_percentile_df['groceries_index_scaled_q3'] = pd.to_numeric(salary_percentile_df['groceries_index_scaled_q3'], errors='coerce')\n",
    "salary_percentile_df['restuarant_price_index_q3'] = pd.to_numeric(salary_percentile_df['restuarant_price_index_q3'], errors='coerce')\n",
    "\n",
    "    \n",
    "    \n",
    "print(salary_percentile_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a6bec",
   "metadata": {},
   "source": [
    "Finding top 5 of each index for each salary measyre, which returns all columnns.\n",
    "Remove all columns except the residency and the column its actually the top 5 of.\n",
    "\n",
    "Then a graph was created to display this and the top 5 countries were printed.\n",
    "\n",
    "This was done in the next three cells for the first quantile, median and third quantile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_cost_of_living_q1 = salary_percentile_df.nlargest(5, 'cost_of_living_scaled_q1')    \n",
    "top_5_cost_of_living_q1 = top_5_cost_of_living_q1[['employee_residence', 'cost_of_living_scaled_q1']]\n",
    "\n",
    "\n",
    "top_5_rent_index_scaled_q1 = salary_percentile_df.nlargest(5, 'rent_index_scaled_q1') \n",
    "top_5_rent_index_scaled_q1  = top_5_rent_index_scaled_q1[['employee_residence', 'rent_index_scaled_q1']]\n",
    "\n",
    "\n",
    "top_5_cost_of_living_plus_rent_index_scaled_q1= salary_percentile_df.nlargest(5, 'cost_of_living_plus_rent_index_scaled_q1')\n",
    "top_5_cost_of_living_plus_rent_index_scaled_q1 = top_5_cost_of_living_plus_rent_index_scaled_q1[['employee_residence', 'cost_of_living_plus_rent_index_scaled_q1']]\n",
    "\n",
    "\n",
    "top_5_groceries_index_scaled_q1 = salary_percentile_df.nlargest(5, 'groceries_index_scaled_q1')\n",
    "top_5_groceries_index_scaled_q1 = top_5_groceries_index_scaled_q1[['employee_residence', 'groceries_index_scaled_q1']]\n",
    "\n",
    "\n",
    "top_5_restuarant_price_index_q1 = salary_percentile_df.nlargest(5, 'restuarant_price_index_q1')\n",
    "top_5_restuarant_price_index_q1 = top_5_restuarant_price_index_q1[['employee_residence', 'restuarant_price_index_q1']]\n",
    "    \n",
    "\n",
    "#merging\n",
    "top_5_merged_q1 = pd.merge(top_5_cost_of_living_q1 , top_5_rent_index_scaled_q1 , how='outer', on='employee_residence')\n",
    "top_5_merged_q1 = pd.merge(top_5_merged_q1 , top_5_cost_of_living_plus_rent_index_scaled_q1 , how='outer', on='employee_residence')\n",
    "top_5_merged_q1 = pd.merge(top_5_merged_q1 , top_5_groceries_index_scaled_q1 , how='outer', on='employee_residence')\n",
    "top_5_merged_q1 = pd.merge(top_5_merged_q1 , top_5_restuarant_price_index_q1 , how='outer', on='employee_residence')\n",
    "    \n",
    "top_5_merged_q1['country']=''\n",
    "\n",
    "for idx, country_code in enumerate(top_5_merged_q1['employee_residence']):\n",
    "    for key, value in country_code_dict.items():\n",
    "        if country_code == value:\n",
    "            top_5_merged_q1['country'][idx] = key\n",
    "            \n",
    "\n",
    "top_5_merged_q1 = top_5_merged_q1.drop(['employee_residence'], axis = 1)\n",
    "\n",
    "\n",
    "# convert to long (tidy) form\n",
    "top_5_merged_q1_melted = top_5_merged_q1.melt('country', var_name='index_q1d', value_name='scaled_salary')\n",
    "legend_labels = ['Cost of Living', 'Rent Index', \n",
    "        'Cost of Living Plus Rent Index', \n",
    "        'Groceries Index', \n",
    "        'Restaurant Price Index']\n",
    "\n",
    "sns.scatterplot(data= top_5_merged_q1_melted, x ='country', y=\"scaled_salary\",\n",
    "                hue=\"index_q1d\", legend = 'full',  palette=sns.color_palette(\"Set1\", 5))\n",
    "plt.title('Top 5 Countries using the First Quantile Salaries Scaled to each Cost Index')\n",
    "plt.xlabel(\"Country\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Salary Scaled by Cost of Index\")\n",
    "plt.legend(title='Cost of Index', loc='upper right', \n",
    "           labels = legend_labels)                \n",
    "plt.show()\n",
    "\n",
    "\n",
    "# print countries of top 5 using print_countries function\n",
    "\n",
    "print('In terms of the first quantile the following are the lists of countries where salary goes the farthest:\\n')\n",
    "print_countries('Cost of Living', top_5_cost_of_living_q1)\n",
    "print_countries('Rent', top_5_rent_index_scaled_q1)\n",
    "print_countries('Cost of Living plus Rent', top_5_cost_of_living_plus_rent_index_scaled_q1)\n",
    "print_countries('Groceries', top_5_groceries_index_scaled_q1)\n",
    "print_countries('Restaurant Price', top_5_restuarant_price_index_q1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32b457",
   "metadata": {},
   "source": [
    "Get actual country name using the country code dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d71de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_merged['country']=''\n",
    "\n",
    "for idx, country_code in enumerate(top_5_merged['employee_residence']):\n",
    "    for key, value in country_code_dict.items():\n",
    "        if country_code == value:\n",
    "            top_5_merged['country'][idx] = key\n",
    "            \n",
    "\n",
    "top_5_merged = top_5_merged.drop(['employee_residence'], axis = 1)\n",
    "\n",
    "print(top_5_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caceb3d",
   "metadata": {},
   "source": [
    "print countries of top 5 using print_countries function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_countries('Cost of Living', top_5_cost_of_living)\n",
    "print_countries('Rent', top_5_rent_index_scaled)\n",
    "print_countries('Cost of Living plus Rent', top_5_cost_of_living_plus_rent_index_scaled)\n",
    "print_countries('Groceries', top_5_groceries_index_scaled)\n",
    "print_countries('Restaurant Price', top_5_restuarant_price_index )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24810d",
   "metadata": {},
   "source": [
    "Create graphic of top 5 for each index.\n",
    "\n",
    "First tidy the data to be able sort of the type of index\n",
    "\n",
    "Then create scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_merged_melted = top_5_merged.melt('country', var_name='index_measured', value_name='scaled_salary')\n",
    "legend_labels = ['Cost of Living', 'Rent Index', \n",
    "        'Cost of Living Plus Rent Index', \n",
    "        'Groceries Index', \n",
    "        'Restaurant Price Index']\n",
    "\n",
    "sns.scatterplot(data= top_5_merged_melted, x ='country', y=\"scaled_salary\",\n",
    "                hue=\"index_measured\")\n",
    "plt.title('Top 5 Countries with Salaries Scaled to each Cost Index')\n",
    "plt.xlabel(\"Country\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Salary Scaled by Cost of Index\")\n",
    "plt.legend(title='Cost of Index', loc='upper right', \n",
    "           labels = legend_labels)                \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440fcc11",
   "metadata": {},
   "source": [
    "The United States was top 1 or 2 on each index. This was for the US as a whole. \n",
    "Now I consider just the US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff35f5d",
   "metadata": {},
   "source": [
    "Go back to salary_df and cost_of_living_df and filter for just US\n",
    "\n",
    "add 3rd quartile to us salary information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe09346",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_us_df = salary_df[salary_df['employee_residence']=='US']\n",
    "\n",
    "salary_us_third_quartile_df = salary_us_df.groupby(['city', 'state']).agg(\n",
    "    third_quantile = ('salary_in_2023' , lambda x: np.percentile(x, q=75))       \n",
    "    )\n",
    "\n",
    "cost_of_living_us_df = cost_of_living_df[cost_of_living_df['employee_residence']=='US']\n",
    "\n",
    "print(salary_us_third_quartile_df.head())\n",
    "print(cost_of_living_us_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c0e917",
   "metadata": {},
   "source": [
    "Note there are no duplicate cities in the cost of living index data, \n",
    "so unlike when grouped by country there is no measures of central tendency to \n",
    "calculate when we look at cities individually.\n",
    "\n",
    "merge cost of living and salary data, then scale salary by each cost of living \n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c31edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_salary_cost_of_living_merge_df = pd.merge(salary_us_third_quartile_df , \n",
    "                                             cost_of_living_us_df,\n",
    "                                             how='outer', on=['city', 'state'])\n",
    "\n",
    "print(us_salary_cost_of_living_merge_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c05b0bc",
   "metadata": {},
   "source": [
    "remove the rank column which is all nan\n",
    "\n",
    "drops rows that contain nan as they either are missing salary or index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37616bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_salary_cost_of_living_merge_drop_df= us_salary_cost_of_living_merge_df.drop(['Rank'], axis = 1)\n",
    "\n",
    "us_salary_cost_of_living_merge_drop_df = us_salary_cost_of_living_merge_drop_df.dropna(axis = 0)\n",
    "\n",
    "us_salary_cost_of_living_merge_drop_df= us_salary_cost_of_living_merge_drop_df.reset_index(drop=True)\n",
    "\n",
    "print(us_salary_cost_of_living_merge_drop_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128e401",
   "metadata": {},
   "source": [
    "Calculate scaled salaries for each index and convert to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_salary_cost_of_living_merge_drop_df['cost_of_living_scaled']=''\n",
    "us_salary_cost_of_living_merge_drop_df['rent_index_scaled']=''\n",
    "us_salary_cost_of_living_merge_drop_df['cost_of_living_plus_rent_index_scaled']=''\n",
    "us_salary_cost_of_living_merge_drop_df['groceries_index_scaled']=''\n",
    "us_salary_cost_of_living_merge_drop_df['restuarant_price_index']=''    \n",
    "for idx, salary in enumerate(us_salary_cost_of_living_merge_drop_df['third_quantile']):\n",
    "    us_salary_cost_of_living_merge_drop_df['cost_of_living_scaled'][idx] = salary*100/us_salary_cost_of_living_merge_drop_df['Cost of Living Index'][idx]\n",
    "    us_salary_cost_of_living_merge_drop_df['rent_index_scaled'][idx] = salary*100/us_salary_cost_of_living_merge_drop_df['Rent Index'][idx]\n",
    "    us_salary_cost_of_living_merge_drop_df['cost_of_living_plus_rent_index_scaled'][idx] = salary*100/us_salary_cost_of_living_merge_drop_df['Cost of Living Plus Rent Index'][idx]\n",
    "    us_salary_cost_of_living_merge_drop_df['groceries_index_scaled'][idx] = salary*100/us_salary_cost_of_living_merge_drop_df['Groceries Index'][idx]\n",
    "    us_salary_cost_of_living_merge_drop_df['restuarant_price_index'][idx] = salary*100/us_salary_cost_of_living_merge_drop_df['Restaurant Price Index'][idx]\n",
    "\n",
    "us_salary_cost_of_living_merge_drop_df['cost_of_living_scaled'] = pd.to_numeric(us_salary_cost_of_living_merge_drop_df['cost_of_living_scaled'], errors='coerce')\n",
    "us_salary_cost_of_living_merge_drop_df['rent_index_scaled'] = pd.to_numeric(us_salary_cost_of_living_merge_drop_df['rent_index_scaled'], errors='coerce')\n",
    "us_salary_cost_of_living_merge_drop_df['cost_of_living_plus_rent_index_scaled'] = pd.to_numeric(us_salary_cost_of_living_merge_drop_df['cost_of_living_plus_rent_index_scaled'], errors='coerce')\n",
    "us_salary_cost_of_living_merge_drop_df['groceries_index_scaled'] = pd.to_numeric(us_salary_cost_of_living_merge_drop_df['groceries_index_scaled'], errors='coerce')\n",
    "us_salary_cost_of_living_merge_drop_df['restuarant_price_index'] = pd.to_numeric(us_salary_cost_of_living_merge_drop_df['restuarant_price_index'], errors='coerce') \n",
    "\n",
    "print(us_salary_cost_of_living_merge_drop_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142cbf1",
   "metadata": {},
   "source": [
    "finding top 5 of each indice, which returns all columnns.\n",
    "so I removed all columns except the residency \n",
    "and the column its actually the top 5 of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3837052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_cost_of_living_us = us_salary_cost_of_living_merge_drop_df.nlargest(5, 'cost_of_living_scaled')    \n",
    "top_5_cost_of_living_us = top_5_cost_of_living_us[['City', 'cost_of_living_scaled']]\n",
    "\n",
    "\n",
    "top_5_rent_index_scaled_us = us_salary_cost_of_living_merge_drop_df.nlargest(5, 'rent_index_scaled') \n",
    "top_5_rent_index_scaled_us  = top_5_rent_index_scaled_us[['City', 'rent_index_scaled']]\n",
    "\n",
    "\n",
    "top_5_cost_of_living_plus_rent_index_scaled_us = us_salary_cost_of_living_merge_drop_df.nlargest(5, 'cost_of_living_plus_rent_index_scaled')\n",
    "top_5_cost_of_living_plus_rent_index_scaled_us = top_5_cost_of_living_plus_rent_index_scaled_us[['City', 'cost_of_living_plus_rent_index_scaled']]\n",
    "\n",
    "\n",
    "top_5_groceries_index_scaled_us = us_salary_cost_of_living_merge_drop_df.nlargest(5, 'groceries_index_scaled')\n",
    "top_5_groceries_index_scaled_us = top_5_groceries_index_scaled_us[['City', 'groceries_index_scaled']]\n",
    "\n",
    "\n",
    "top_5_restuarant_price_index_us = us_salary_cost_of_living_merge_drop_df.nlargest(5, 'restuarant_price_index')\n",
    "top_5_restuarant_price_index_us = top_5_restuarant_price_index_us[['City', 'restuarant_price_index']]\n",
    "    \n",
    "\n",
    "\n",
    "#merging\n",
    "top_5_merged_us = pd.merge(top_5_cost_of_living_us , top_5_rent_index_scaled_us , how='outer', on='City')\n",
    "top_5_merged_us = pd.merge(top_5_merged_us , top_5_cost_of_living_plus_rent_index_scaled_us , how='outer', on='City')\n",
    "top_5_merged_us = pd.merge(top_5_merged_us , top_5_groceries_index_scaled_us , how='outer', on='City')\n",
    "top_5_merged_us = pd.merge(top_5_merged_us , top_5_restuarant_price_index_us , how='outer', on='City')\n",
    "\n",
    "print(top_5_merged_us)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a0771",
   "metadata": {},
   "source": [
    "Print top 5 cities within the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4abe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cities('Cost of Living', top_5_cost_of_living_us)\n",
    "print('\\n')\n",
    "print_cities('Rent', top_5_rent_index_scaled_us)\n",
    "print('\\n')\n",
    "print_cities('Cost of Living plus Rent', top_5_cost_of_living_plus_rent_index_scaled_us)\n",
    "print('\\n')\n",
    "print_cities('Groceries', top_5_groceries_index_scaled_us)\n",
    "print('\\n')\n",
    "print_cities('Restaurant Price', top_5_restuarant_price_index_us )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0948c",
   "metadata": {},
   "source": [
    "Create graphic of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to long (tidy) form\n",
    "top_5_merged_melted_us = top_5_merged_us.melt('City', var_name='index_measured', value_name='scaled_salary')\n",
    "\n",
    "\n",
    "legend_labels = ['Cost of Living', 'Rent Index', \n",
    "        'Cost of Living Plus Rent Index', \n",
    "        'Groceries Index', \n",
    "        'Restaurant Price Index']\n",
    "\n",
    "sns.scatterplot(data= top_5_merged_melted_us, x ='City', y=\"scaled_salary\",\n",
    "                hue=\"index_measured\")\n",
    "plt.title('Top 5 US Cities with Salaries Scaled to each Cost Index')\n",
    "plt.xlabel(\"City\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Salary Scaled by Cost of Index\")\n",
    "plt.legend(title='Cost of Index', loc='upper right', \n",
    "           labels = legend_labels)                \n",
    "plt.show()                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec5bfd5",
   "metadata": {},
   "source": [
    "What I have learned is that I am not moving anywhere where my salary will go the farthest as I have zero intention of leaving coastal New Hampshire to live in California, the midwest or Texas. (Actually it seems New England was sorely underrepresented in the data.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
